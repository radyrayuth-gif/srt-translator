import streamlit as st
import asyncio
import edge_tts
import io
import re
from datetime import datetime

# --- á€áŸ†áááŸ‹á‘áŸ†á–áŸáš ---
st.set_page_config(page_title="Khmer TTS SRT-Sync", page_icon="ğŸ™ï¸")

def srt_time_to_ms(time_str):
    time_obj = datetime.strptime(time_str.strip().replace(',', '.'), '%H:%M:%S.%f')
    return (time_obj.hour * 3600000) + (time_obj.minute * 60000) + (time_obj.second * 1000) + (time_obj.microsecond // 1000)

def parse_srt(srt_text):
    pattern = r"(\d+)\s+(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\s+(.*?)(?=\n\d+\s+|\Z)"
    matches = re.findall(pattern, srt_text, re.DOTALL)
    subtitles = []
    for m in matches:
        subtitles.append({
            "start": srt_time_to_ms(m[1]),
            "text": m[3].replace('\n', ' ').strip()
        })
    return subtitles

# --- á˜á»áá„á¶ášá”á„áŸ’á€á¾ááŸáŸ†á¡áŸá„ (á€áŸ‚áŸá˜áŸ’ášá½á› SSML) ---
async def generate_synced_audio(subtitles, voice, rate, pitch):
    rate_str = f"{rate:+d}%"
    pitch_str = f"{pitch:+d}Hz"
    
    # á”á„áŸ’á€á¾á SSML String
    ssml_parts = [f"<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='km-KH'>"]
    current_time_ms = 0
    
    for sub in subtitles:
        wait_time_ms = sub["start"] - current_time_ms
        if wait_time_ms > 0:
            ssml_parts.append(f"<break time='{wait_time_ms}ms'/>")
        
        ssml_parts.append(f"<prosody rate='{rate_str}' pitch='{pitch_str}'>{sub['text']}</prosody>")
        # á”áŸ‰á¶á“áŸ‹áŸáŸ’á˜á¶á“áá¶á¢ááŸ’áá”á‘ááŸ’á›á¸áŸ—á”áŸ’ášá¾á–áŸá› áŸ¡ áœá·á“á¶á‘á¸ áŠá¾á˜áŸ’á”á¸á‚áá“á¶ Break á”á“áŸ’á‘á¶á”áŸ‹
        current_time_ms = sub["start"] + 1000 

    ssml_parts.append("</speak>")
    ssml_string = "".join(ssml_parts)
    
    # á€áŸ‚áŸá˜áŸ’ášá½á›ááŸ’ášá„áŸ‹á“áŸáŸ‡áŸ– á”áŸ’ášá¾ Communicate á‡á¶á˜á½á™ SSML á•áŸ’á‘á¶á›áŸ‹
    communicate = edge_tts.Communicate(ssml_string, voice) 
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    return audio_data

# --- UI ---
st.title("ğŸ™ï¸ á€á˜áŸ’á˜áœá·á’á¸á¢á¶á“áá¶á˜á–áŸá›áœáŸá›á¶ (Fixed)")

with st.sidebar:
    st.header("âš™ï¸ á€á¶ášá€áŸ†áááŸ‹")
    voice_choice = st.selectbox("á‡áŸ’ášá¾áŸášá¾áŸáŸáŸ†á¡áŸá„:", ["áŸáŸ’ášá¸á˜á»áŸ† (Sreymom)", "á–á·áŸá·áŠáŸ’á‹ (Piseth)"])
    voice_id = "km-KH-SreymomNeural" if "áŸáŸ’ášá¸á˜á»áŸ†" in voice_choice else "km-KH-PisethNeural"
    speed_rate = st.slider("á›áŸ’á”á¿á“á¢á¶á“ (%)", -50, 50, 0, 5)
    pitch_val = st.slider("á€á˜áŸ’ášá·ááŸáŸ†á¡áŸá„ (Pitch)", -20, 20, 0, 1)

srt_input = st.text_area("á”á·á‘á—áŸ’á‡á¶á”áŸ‹á¢ááŸ’áá”á‘ SRT á“áŸ…á‘á¸á“áŸáŸ‡:", height=300)

if st.button("ğŸš€ á”á„áŸ’á€á¾ááŸáŸ†á¡áŸá„"):
    if srt_input.strip():
        with st.spinner("á€áŸ†á–á»á„á”á„áŸ’á€á¾á..."):
            try:
                subs = parse_srt(srt_input)
                if subs:
                    # á áŸ…á”áŸ’ášá¾á˜á»áá„á¶ášáŠáŸ‚á›á”á¶á“á€áŸ‚áŸá˜áŸ’ášá½á›
                    audio_bytes = asyncio.run(generate_synced_audio(subs, voice_id, speed_rate, pitch_val))
                    st.success("ášá½á…ášá¶á›áŸ‹!")
                    st.audio(audio_bytes, format="audio/mp3")
                    st.download_button("ğŸ“¥ á‘á¶á‰á™á€ MP3", audio_bytes, "synced_audio.mp3")
                else:
                    st.error("á‘á˜áŸ’ášá„áŸ‹ SRT á˜á·á“ááŸ’ášá¹á˜ááŸ’ášá¼áœ!")
            except Exception as e:
                st.error(f"á€áŸ†á á»áŸáŸ– {e}")
