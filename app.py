import streamlit as st
import asyncio
import edge_tts
import re
import io
from pydub import AudioSegment

st.set_page_config(page_title="Khmer Voice Sync Pro", page_icon="ğŸ™ï¸")

# áŸ¡. á˜á»áá„á¶ášá”áŸ†á”áŸ’á›áŸ‚á„á˜áŸ‰áŸ„á„ SRT á‘áŸ…á‡á¶á˜á¸á›á¸áœá·á“á¶á‘á¸ (ms)
def time_to_ms(time_str):
    h, m, s = time_str.replace(',', '.').split(':')
    return int((int(h) * 3600 + int(m) * 60 + float(s)) * 1000)

# áŸ¢. á˜á»áá„á¶ášá•á›á·ááŸáŸ†á¡áŸá„áŠá»áŸ†áŸ—
async def get_audio_segment(text, voice):
    communicate = edge_tts.Communicate(text, voice)
    audio_data = b""
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data += chunk["data"]
    return AudioSegment.from_file(io.BytesIO(audio_data), format="mp3")

st.title("ğŸ™ï¸ Khmer Voice Sync (áŠá¼á… VoiceRTool)")
st.write("á”á·á‘á—áŸ’á‡á¶á”áŸ‹ SRT ášá½á…á‘á¶á‰á™á€ File MP3 áŠáŸ‚á› Sync ášá½á…á‡á¶áŸáŸ’ášáŸá…")

voice_id = st.sidebar.selectbox("á‡áŸ’ášá¾áŸášá¾áŸáŸáŸ†á¡áŸá„:", ["km-KH-SreymomNeural", "km-KH-PisethNeural"])
srt_input = st.text_area("á”á·á‘á—áŸ’á‡á¶á”áŸ‹á¢ááŸ’áá”á‘ SRT á‘á¸á“áŸáŸ‡:", height=300)

if st.button("ğŸš€ á…á¶á”áŸ‹á•áŸ’áŠá¾á˜á•á›á·á File ášá½á˜á‚áŸ’á“á¶"):
    if srt_input:
        with st.spinner("á€áŸ†á–á»á„á•á›á·á á“á·á„á”á‰áŸ’á…á¼á›áŸáŸ†á¡áŸá„áá¶á˜á“á¶á‘á¸..."):
            # á…áŸ’ášáŸ„áŸ‡á™á€á˜áŸ‰áŸ„á„ á“á·á„á¢ááŸ’áá”á‘
            blocks = re.split(r'\n\s*\n', srt_input.strip())
            final_audio = AudioSegment.silent(duration=0)
            
            for block in blocks:
                lines = block.strip().split('\n')
                time_line = next((l for l in lines if "-->" in l), None)
                text_lines = [l.strip() for l in lines if "-->" not in l and not l.strip().isdigit()]
                
                if time_line and text_lines:
                    start_time_str = time_line.split("-->")[0].strip()
                    start_ms = time_to_ms(start_time_str)
                    text = " ".join(text_lines)
                    
                    # á•á›á·ááŸáŸ†á¡áŸá„áŠá»áŸ†
                    segment = asyncio.run(get_audio_segment(text, voice_id))
                    
                    # á”á“áŸ’ááŸ‚á˜á—á¶á–áŸáŸ’á„á¶ááŸ‹á”á¾á˜á·á“á‘á¶á“áŸ‹áŠá›áŸ‹á˜áŸ‰áŸ„á„á¢á¶á“
                    if len(final_audio) < start_ms:
                        final_audio += AudioSegment.silent(duration=start_ms - len(final_audio))
                    
                    # áŠá¶á€áŸ‹áŸáŸ†á¡áŸá„á…á¼á›á€áŸ’á“á»á„ Timeline
                    final_audio = final_audio.overlay(segment, position=start_ms)

            # Export á‡á¶ File ááŸ‚á˜á½á™
            out_buffer = io.BytesIO()
            final_audio.export(out_buffer, format="mp3")
            out_buffer.seek(0)
            audio_bytes = out_buffer.read()

            if audio_bytes:
                st.audio(audio_bytes, format="audio/mp3")
                st.download_button("ğŸ“¥ á‘á¶á‰á™á€ File MP3 áŠáŸ‚á› Sync ášá½á…", audio_bytes, "khmer_sync_audio.mp3")
                st.success("á‡áŸ„á‚á‡áŸá™! áŸáŸ†á¡áŸá„á¢á¶á“ááŸ’ášá¼áœáá¶á˜á“á¶á‘á¸ SRT á‘á¶áŸ†á„á¢áŸáŸ‹áŸ”")
    else:
        st.warning("áŸá¼á˜á”á‰áŸ’á…á¼á› SRT!")
