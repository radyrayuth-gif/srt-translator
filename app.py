import streamlit as st
import asyncio
import edge_tts
import io
import re
from pydub import AudioSegment
from datetime import datetime

st.set_page_config(page_title="Khmer Perfect Sync", page_icon="ğŸ™ï¸")

def srt_time_to_ms(time_str):
    time_obj = datetime.strptime(time_str.strip().replace(',', '.'), '%H:%M:%S.%f')
    return (time_obj.hour * 3600000) + (time_obj.minute * 60000) + (time_obj.second * 1000) + (time_obj.microsecond // 1000)

def parse_srt(srt_text):
    # Regex á“áŸáŸ‡á‡á½á™á›á»á”á›áŸáášáŸ€á„á…áŸá‰ áŠá¾á˜áŸ’á”á¸á€á»áŸ†á±áŸ’á™ AI á¢á¶á“á›áŸá áŸ¡, áŸ¢, áŸ£
    pattern = r"(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\s+(.*?)(?=\n\d{2}:\d{2}:\d{2},\d{3}|\n\n\d+|$)"
    matches = re.findall(pattern, srt_text, re.DOTALL)
    subtitles = []
    for m in matches:
        text_only = m[2].strip()
        if text_only:
            subtitles.append({"start": srt_time_to_ms(m[0]), "text": text_only})
    return subtitles

async def generate_audio(subtitles, voice, rate, pitch):
    combined = AudioSegment.silent(duration=0)
    rate_str = f"{rate:+d}%"
    pitch_str = f"{pitch:+d}Hz"
    
    for sub in subtitles:
        # á”á„áŸ’á€á¾ááŸáŸ†á¡áŸá„á¢á¶á“ (á˜á·á“á”áŸ’ášá¾ SSML áŠá¾á˜áŸ’á”á¸á€á»áŸ†á±áŸ’á™á¢á¶á“ Tag á…áŸá‰á˜á€á€áŸ’ášáŸ…)
        communicate = edge_tts.Communicate(sub["text"], voice, rate=rate_str, pitch=pitch_str)
        temp_buf = io.BytesIO()
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                temp_buf.write(chunk["data"])
        
        temp_buf.seek(0)
        segment = AudioSegment.from_file(temp_buf, format="mp3")
        
        # á”á‰áŸ’á…á¼á›á—á¶á–áŸáŸ’á„á¶ááŸ‹á±áŸ’á™ááŸ’ášá¼áœáá¶á˜áœá·á“á¶á‘á¸á…á¶á”áŸ‹á•áŸ’áŠá¾á˜á€áŸ’á“á»á„ SRT
        silence_needed = sub["start"] - len(combined)
        if silence_needed > 0:
            combined += AudioSegment.silent(duration=silence_needed)
        
        combined = combined.overlay(segment, position=sub["start"])
        if len(combined) < sub["start"] + len(segment):
            combined += AudioSegment.silent(duration=(sub["start"] + len(segment)) - len(combined))
            
    out_buf = io.BytesIO()
    combined.export(out_buf, format="mp3")
    return out_buf.getvalue()

st.title("ğŸ™ï¸ á€á˜áŸ’á˜áœá·á’á¸á¢á¶á“áá¶á˜áœá·á“á¶á‘á¸ (Fixed)")
voice_id = st.sidebar.selectbox("áŸáŸ†á¡áŸá„:", ["km-KH-SreymomNeural", "km-KH-PisethNeural"])
srt_input = st.text_area("á”á·á‘á—áŸ’á‡á¶á”áŸ‹ SRT á‘á¸á“áŸáŸ‡:", height=300)

if st.button("ğŸš€ á•á›á·ááŸáŸ†á¡áŸá„"):
    if srt_input:
        subs = parse_srt(srt_input)
        audio_data = asyncio.run(generate_audio(subs, voice_id, 0, 0))
        st.audio(audio_data, format="audio/mp3")
